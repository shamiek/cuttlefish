package edu.purdue.cuttlefish.evaluation.tpch

import edu.purdue.cuttlefish.spark.{Config => SparkConfig}
import org.apache.spark.sql.SparkSession

object Config {

    val TABLE_NAMES = Seq(
        "customer", "lineitem", "nation", "orders",
        "part", "partsupp", "region", "supplier")

    object ExecutionMode extends Enumeration {
        val
        // textfiles as generated by tpc-h dgen script
        TXT,
        // plaintext files loaded using parquet after parsed from textfiles
        PTXT,
        // unoptimized PHE mode
        PHE,
        // optimized PHE
        CUTTLEFISH
        = Value
    }

    var executionModeMap = Map(
        ExecutionMode.TXT -> "tbl",
        ExecutionMode.PTXT -> "ptxt",
        ExecutionMode.PHE -> "phe",
        ExecutionMode.CUTTLEFISH -> "cuttlefish"
    )

    def getPath(executionMode: ExecutionMode.Value, name: String) = {
        val dir = if (SparkConfig.fileSystem == SparkConfig.FileSystem.LOCAL)
//            SparkConfig.getLocalPath(SparkConfig.CUTTLEFISH_HOME + "/resources/data_input/tblSilo/10MBtBL")
//            SparkConfig.getLocalPath(SparkConfig.CUTTLEFISH_HOME + "/resources/data_input/tblSilo/10MBtBL")
            SparkConfig.getLocalPath(SparkConfig.CUTTLEFISH_HOME + "/resources/data_input/tblSilo/100MBtBL")
        else
            SparkConfig.getHDFSPath("/tpch")

        dir + "/" + name + "." + executionModeMap(executionMode)
    }

    def getTable(spark: SparkSession, executionMode: ExecutionMode.Value, tableName: String) = {
        val path = getPath(executionMode, tableName)
        spark.read.parquet(path)
    }

}
